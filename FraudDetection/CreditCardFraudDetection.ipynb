{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb5e7f5c-5754-4193-ba47-b08298ba49cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 22:54:58.320159: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-05 22:54:58.320176: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import classification_report\n",
    "#Install packages if required\n",
    "#import pip\n",
    "#pip.main(['install', 'sklearn'])\n",
    "#pip.main(['install' , 'tensorflow'])\n",
    "from tensorflow.python.keras.layers import InputLayer, Dense, BatchNormalization\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daa897c4-0455-4cbc-bdaf-831eaf02b4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/creditcard.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceb0371d-4878-4b0d-95a9-1ddb5b57a2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "effdc3aa-7596-4592-a17c-69f01c54b8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.918649e-15</td>\n",
       "      <td>5.682686e-16</td>\n",
       "      <td>-8.761736e-15</td>\n",
       "      <td>2.811118e-15</td>\n",
       "      <td>-1.552103e-15</td>\n",
       "      <td>2.040130e-15</td>\n",
       "      <td>-1.698953e-15</td>\n",
       "      <td>-1.893285e-16</td>\n",
       "      <td>-3.147640e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.473120e-16</td>\n",
       "      <td>8.042109e-16</td>\n",
       "      <td>5.282512e-16</td>\n",
       "      <td>4.456271e-15</td>\n",
       "      <td>1.426896e-15</td>\n",
       "      <td>1.701640e-15</td>\n",
       "      <td>-3.662252e-16</td>\n",
       "      <td>-1.217809e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.918649e-15  5.682686e-16 -8.761736e-15  2.811118e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552103e-15  2.040130e-15 -1.698953e-15 -1.893285e-16 -3.147640e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.473120e-16  8.042109e-16  5.282512e-16  4.456271e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.426896e-15  1.701640e-15 -3.662252e-16 -1.217809e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc549eed-5270-480c-8d9a-aed675cb6f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>1.783274</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.269825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>4.983721</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>1.418291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0.670579</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>0.999965</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>-0.296653</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>0.999971</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>0.038986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>0.999977</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>0.641096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>0.999977</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>-0.167680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>2.724796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0       0.000000  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1       0.000000   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2       0.000006  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3       0.000006  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4       0.000012  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  0.999965 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  0.999971  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  0.999977   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  0.999977  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  1.000000  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28    Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  1.783274   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724 -0.269825   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  4.983721   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  1.418291   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153  0.670579   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731 -0.296653   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527  0.038986   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561  0.641096   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533 -0.167680   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  2.724796   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df.copy()\n",
    "new_df['Amount'] = RobustScaler().fit_transform(new_df['Amount'].to_numpy().reshape(-1, 1))\n",
    "time = new_df['Time']\n",
    "new_df['Time'] = (time - time.min()) / (time.max() - time.min())\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "601aabd0-508c-43cc-a421-0b4f1343f6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169876</th>\n",
       "      <td>0.693938</td>\n",
       "      <td>-0.611712</td>\n",
       "      <td>-0.769705</td>\n",
       "      <td>-0.149759</td>\n",
       "      <td>-0.224877</td>\n",
       "      <td>2.028577</td>\n",
       "      <td>-2.019887</td>\n",
       "      <td>0.292491</td>\n",
       "      <td>-0.523020</td>\n",
       "      <td>0.358468</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075208</td>\n",
       "      <td>0.045536</td>\n",
       "      <td>0.380739</td>\n",
       "      <td>0.023440</td>\n",
       "      <td>-2.220686</td>\n",
       "      <td>-0.201146</td>\n",
       "      <td>0.066501</td>\n",
       "      <td>0.221180</td>\n",
       "      <td>-0.282401</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127467</th>\n",
       "      <td>0.453377</td>\n",
       "      <td>-0.814682</td>\n",
       "      <td>1.319219</td>\n",
       "      <td>1.329415</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>-0.284871</td>\n",
       "      <td>-0.653985</td>\n",
       "      <td>0.321552</td>\n",
       "      <td>0.435975</td>\n",
       "      <td>-0.704298</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128619</td>\n",
       "      <td>-0.368565</td>\n",
       "      <td>0.090660</td>\n",
       "      <td>0.401147</td>\n",
       "      <td>-0.261034</td>\n",
       "      <td>0.080621</td>\n",
       "      <td>0.162427</td>\n",
       "      <td>0.059456</td>\n",
       "      <td>-0.279746</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137900</th>\n",
       "      <td>0.476770</td>\n",
       "      <td>-0.318193</td>\n",
       "      <td>1.118618</td>\n",
       "      <td>0.969864</td>\n",
       "      <td>-0.127052</td>\n",
       "      <td>0.569563</td>\n",
       "      <td>-0.532484</td>\n",
       "      <td>0.706252</td>\n",
       "      <td>-0.064966</td>\n",
       "      <td>-0.463271</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.305402</td>\n",
       "      <td>-0.774704</td>\n",
       "      <td>-0.123884</td>\n",
       "      <td>-0.495687</td>\n",
       "      <td>-0.018148</td>\n",
       "      <td>0.121679</td>\n",
       "      <td>0.249050</td>\n",
       "      <td>0.092516</td>\n",
       "      <td>-0.294977</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21513</th>\n",
       "      <td>0.183556</td>\n",
       "      <td>-1.328271</td>\n",
       "      <td>1.018378</td>\n",
       "      <td>1.775426</td>\n",
       "      <td>-1.574193</td>\n",
       "      <td>-0.117696</td>\n",
       "      <td>-0.457733</td>\n",
       "      <td>0.681867</td>\n",
       "      <td>-0.031641</td>\n",
       "      <td>0.383872</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.220815</td>\n",
       "      <td>-0.419013</td>\n",
       "      <td>-0.239197</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>0.232829</td>\n",
       "      <td>0.814177</td>\n",
       "      <td>0.098797</td>\n",
       "      <td>-0.004273</td>\n",
       "      <td>-0.084119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134700</th>\n",
       "      <td>0.468326</td>\n",
       "      <td>1.276712</td>\n",
       "      <td>0.617120</td>\n",
       "      <td>-0.578014</td>\n",
       "      <td>0.879173</td>\n",
       "      <td>0.061706</td>\n",
       "      <td>-1.472002</td>\n",
       "      <td>0.373692</td>\n",
       "      <td>-0.287204</td>\n",
       "      <td>-0.084482</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.160161</td>\n",
       "      <td>-0.430404</td>\n",
       "      <td>-0.076738</td>\n",
       "      <td>0.258708</td>\n",
       "      <td>0.552170</td>\n",
       "      <td>0.370701</td>\n",
       "      <td>-0.034255</td>\n",
       "      <td>0.041709</td>\n",
       "      <td>-0.296793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21440</th>\n",
       "      <td>0.183261</td>\n",
       "      <td>-2.986845</td>\n",
       "      <td>-8.663978</td>\n",
       "      <td>-1.910863</td>\n",
       "      <td>0.664058</td>\n",
       "      <td>-3.934875</td>\n",
       "      <td>0.861269</td>\n",
       "      <td>1.647511</td>\n",
       "      <td>-0.480963</td>\n",
       "      <td>-1.546866</td>\n",
       "      <td>...</td>\n",
       "      <td>1.252092</td>\n",
       "      <td>-0.993085</td>\n",
       "      <td>-2.173147</td>\n",
       "      <td>0.145570</td>\n",
       "      <td>-0.235062</td>\n",
       "      <td>-0.227411</td>\n",
       "      <td>-0.382702</td>\n",
       "      <td>0.404045</td>\n",
       "      <td>32.002515</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117583</th>\n",
       "      <td>0.432480</td>\n",
       "      <td>0.937083</td>\n",
       "      <td>-0.849673</td>\n",
       "      <td>0.524186</td>\n",
       "      <td>-0.020031</td>\n",
       "      <td>-0.606327</td>\n",
       "      <td>0.692302</td>\n",
       "      <td>-0.463724</td>\n",
       "      <td>0.148857</td>\n",
       "      <td>0.785062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143322</td>\n",
       "      <td>-0.479981</td>\n",
       "      <td>-0.237902</td>\n",
       "      <td>-0.715247</td>\n",
       "      <td>0.251418</td>\n",
       "      <td>0.975406</td>\n",
       "      <td>-0.060168</td>\n",
       "      <td>0.023771</td>\n",
       "      <td>2.086495</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73349</th>\n",
       "      <td>0.318852</td>\n",
       "      <td>-1.149963</td>\n",
       "      <td>1.696462</td>\n",
       "      <td>1.637114</td>\n",
       "      <td>2.658991</td>\n",
       "      <td>-0.021502</td>\n",
       "      <td>0.192287</td>\n",
       "      <td>0.205204</td>\n",
       "      <td>0.588754</td>\n",
       "      <td>-1.187820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025147</td>\n",
       "      <td>0.086506</td>\n",
       "      <td>-0.262748</td>\n",
       "      <td>0.321538</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.210343</td>\n",
       "      <td>-0.162047</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>-0.201495</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267336</th>\n",
       "      <td>0.941757</td>\n",
       "      <td>1.754554</td>\n",
       "      <td>-0.699398</td>\n",
       "      <td>-0.076332</td>\n",
       "      <td>0.443915</td>\n",
       "      <td>-0.672082</td>\n",
       "      <td>0.389061</td>\n",
       "      <td>-0.807534</td>\n",
       "      <td>0.202915</td>\n",
       "      <td>0.858635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141950</td>\n",
       "      <td>0.358412</td>\n",
       "      <td>0.259748</td>\n",
       "      <td>0.746839</td>\n",
       "      <td>-0.560808</td>\n",
       "      <td>0.104636</td>\n",
       "      <td>-0.005853</td>\n",
       "      <td>-0.019622</td>\n",
       "      <td>1.017257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128037</th>\n",
       "      <td>0.454743</td>\n",
       "      <td>-0.707635</td>\n",
       "      <td>0.493302</td>\n",
       "      <td>2.648089</td>\n",
       "      <td>1.064807</td>\n",
       "      <td>-0.680271</td>\n",
       "      <td>1.183838</td>\n",
       "      <td>0.169413</td>\n",
       "      <td>0.074553</td>\n",
       "      <td>1.247988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.102350</td>\n",
       "      <td>0.323975</td>\n",
       "      <td>-0.172601</td>\n",
       "      <td>0.126965</td>\n",
       "      <td>-0.001998</td>\n",
       "      <td>-0.398741</td>\n",
       "      <td>-0.385589</td>\n",
       "      <td>-0.205589</td>\n",
       "      <td>0.500245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "169876  0.693938 -0.611712 -0.769705 -0.149759 -0.224877  2.028577 -2.019887   \n",
       "127467  0.453377 -0.814682  1.319219  1.329415  0.027273 -0.284871 -0.653985   \n",
       "137900  0.476770 -0.318193  1.118618  0.969864 -0.127052  0.569563 -0.532484   \n",
       "21513   0.183556 -1.328271  1.018378  1.775426 -1.574193 -0.117696 -0.457733   \n",
       "134700  0.468326  1.276712  0.617120 -0.578014  0.879173  0.061706 -1.472002   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "21440   0.183261 -2.986845 -8.663978 -1.910863  0.664058 -3.934875  0.861269   \n",
       "117583  0.432480  0.937083 -0.849673  0.524186 -0.020031 -0.606327  0.692302   \n",
       "73349   0.318852 -1.149963  1.696462  1.637114  2.658991 -0.021502  0.192287   \n",
       "267336  0.941757  1.754554 -0.699398 -0.076332  0.443915 -0.672082  0.389061   \n",
       "128037  0.454743 -0.707635  0.493302  2.648089  1.064807 -0.680271  1.183838   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "169876  0.292491 -0.523020  0.358468  ... -0.075208  0.045536  0.380739   \n",
       "127467  0.321552  0.435975 -0.704298  ... -0.128619 -0.368565  0.090660   \n",
       "137900  0.706252 -0.064966 -0.463271  ... -0.305402 -0.774704 -0.123884   \n",
       "21513   0.681867 -0.031641  0.383872  ... -0.220815 -0.419013 -0.239197   \n",
       "134700  0.373692 -0.287204 -0.084482  ... -0.160161 -0.430404 -0.076738   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "21440   1.647511 -0.480963 -1.546866  ...  1.252092 -0.993085 -2.173147   \n",
       "117583 -0.463724  0.148857  0.785062  ... -0.143322 -0.479981 -0.237902   \n",
       "73349   0.205204  0.588754 -1.187820  ...  0.025147  0.086506 -0.262748   \n",
       "267336 -0.807534  0.202915  0.858635  ...  0.141950  0.358412  0.259748   \n",
       "128037  0.169413  0.074553  1.247988  ... -0.102350  0.323975 -0.172601   \n",
       "\n",
       "             V24       V25       V26       V27       V28     Amount  Class  \n",
       "169876  0.023440 -2.220686 -0.201146  0.066501  0.221180  -0.282401      0  \n",
       "127467  0.401147 -0.261034  0.080621  0.162427  0.059456  -0.279746      0  \n",
       "137900 -0.495687 -0.018148  0.121679  0.249050  0.092516  -0.294977      0  \n",
       "21513   0.009967  0.232829  0.814177  0.098797 -0.004273  -0.084119      0  \n",
       "134700  0.258708  0.552170  0.370701 -0.034255  0.041709  -0.296793      0  \n",
       "...          ...       ...       ...       ...       ...        ...    ...  \n",
       "21440   0.145570 -0.235062 -0.227411 -0.382702  0.404045  32.002515      0  \n",
       "117583 -0.715247  0.251418  0.975406 -0.060168  0.023771   2.086495      0  \n",
       "73349   0.321538  0.341667  0.210343 -0.162047  0.031193  -0.201495      0  \n",
       "267336  0.746839 -0.560808  0.104636 -0.005853 -0.019622   1.017257      0  \n",
       "128037  0.126965 -0.001998 -0.398741 -0.385589 -0.205589   0.500245      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = new_df.sample(frac=1, random_state=1)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2c79666-f119-444f-b94f-4e6629a19a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    239589\n",
       " 1       411\n",
       " Name: Class, dtype: int64,\n",
       " 0    21955\n",
       " 1       45\n",
       " Name: Class, dtype: int64,\n",
       " 0    22771\n",
       " 1       36\n",
       " Name: Class, dtype: int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test, val = new_df[:240000], new_df[240000:262000], new_df[262000:]\n",
    "train['Class'].value_counts(), test['Class'].value_counts(), val['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ee48b4e-7dd1-4049-bf54-a203e72a7081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((240000, 31), (22000, 31), (22807, 31))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_np, test_np, val_np = train.to_numpy(), test.to_numpy(), val.to_numpy()\n",
    "train_np.shape, test_np.shape, val_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4deccc04-810d-4140-b1ff-730f9201bffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((240000, 30), (240000,), (22000, 30), (22000,), (22807, 30), (22807,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = train_np[:, :-1], train_np[:, -1]\n",
    "x_test, y_test = test_np[:, :-1], test_np[:, -1]\n",
    "x_val, y_val = val_np[:, :-1], val_np[:, -1]\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a199b9a-9897-4ae2-af25-cc7a1f0d4f8d",
   "metadata": {},
   "source": [
    "## Neural Net Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cc05023-c443-4add-ac10-e0141623c148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 2)                 62        \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 73\n",
      "Trainable params: 69\n",
      "Non-trainable params: 4\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 22:55:34.093323: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-05 22:55:34.093371: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-05 22:55:34.093408: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (stepski): /proc/driver/nvidia/version does not exist\n",
      "2022-02-05 22:55:34.093849: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "shallow_nn = Sequential()\n",
    "shallow_nn.add(InputLayer((x_train.shape[1],)))\n",
    "shallow_nn.add(Dense(2, 'relu'))\n",
    "shallow_nn.add(BatchNormalization())\n",
    "shallow_nn.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "checkpoint = ModelCheckpoint('shallow_nn', save_best_only=True)\n",
    "shallow_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "shallow_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feff9269-94eb-4825-9d4f-f460b4b2ae80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7500/7500 [==============================] - 5s 634us/step - loss: 0.0518 - accuracy: 0.9842 - val_loss: 0.0079 - val_accuracy: 0.9991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 22:55:41.738211: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn/assets\n",
      "Epoch 2/5\n",
      "7500/7500 [==============================] - 5s 628us/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.0113 - val_accuracy: 0.9991\n",
      "Epoch 3/5\n",
      "7500/7500 [==============================] - 5s 625us/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0109 - val_accuracy: 0.9991\n",
      "Epoch 4/5\n",
      "7500/7500 [==============================] - 5s 627us/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0171 - val_accuracy: 0.9991\n",
      "Epoch 5/5\n",
      "7500/7500 [==============================] - 5s 626us/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0106 - val_accuracy: 0.9991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f057879d400>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shallow_nn.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=5, callbacks=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3ecb377-2f41-4b4a-b40b-23c2a2c83983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net_predictions(model, x):\n",
    "  return (model.predict(x).flatten() > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5278555-b083-4b7d-ae1f-1d39e618c581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       1.00      1.00      1.00     22771\n",
      "       Fraud       0.69      0.75      0.72        36\n",
      "\n",
      "    accuracy                           1.00     22807\n",
      "   macro avg       0.85      0.87      0.86     22807\n",
      "weighted avg       1.00      1.00      1.00     22807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, neural_net_predictions(shallow_nn, x_val), target_names=['Not Fraud', 'Fraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff06f7c-ec09-4db4-a6ca-f461de04ae72",
   "metadata": {},
   "source": [
    "## Machine Learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9039ef67-dac4-4d3b-bf31-a97e5c81c55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       1.00      1.00      1.00     22771\n",
      "       Fraud       0.77      0.47      0.59        36\n",
      "\n",
      "    accuracy                           1.00     22807\n",
      "   macro avg       0.89      0.74      0.79     22807\n",
      "weighted avg       1.00      1.00      1.00     22807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=2, n_jobs=-1)\n",
    "rf.fit(x_train, y_train)\n",
    "print(classification_report(y_val, rf.predict(x_val), target_names=['Not Fraud', 'Fraud']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3579d807-2345-4cc2-abbc-bb1b935035fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       1.00      1.00      1.00     22771\n",
      "       Fraud       0.67      0.67      0.67        36\n",
      "\n",
      "    accuracy                           1.00     22807\n",
      "   macro avg       0.83      0.83      0.83     22807\n",
      "weighted avg       1.00      1.00      1.00     22807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=50, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "gbc.fit(x_train, y_train)\n",
    "print(classification_report(y_val, gbc.predict(x_val), target_names=['Not Fraud', 'Fraud']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9f53743-3e72-4990-a481-0af7f31e4cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       1.00      1.00      1.00     22771\n",
      "       Fraud       0.66      0.75      0.70        36\n",
      "\n",
      "    accuracy                           1.00     22807\n",
      "   macro avg       0.83      0.87      0.85     22807\n",
      "weighted avg       1.00      1.00      1.00     22807\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stepski/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC(class_weight='balanced')\n",
    "svc.fit(x_train, y_train)\n",
    "print(classification_report(y_val, svc.predict(x_val), target_names=['Not Fraud', 'Fraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60d2897-a9d2-4c6e-9fe2-a0d00f5a2466",
   "metadata": {},
   "source": [
    "## Balancing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90a8fb98-ad50-456d-a1b9-525a85a076d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    284315\n",
       " Name: Class, dtype: int64,\n",
       " 1    492\n",
       " Name: Class, dtype: int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_frauds = new_df.query('Class == 0')\n",
    "frauds = new_df.query('Class == 1')\n",
    "not_frauds['Class'].value_counts(), frauds['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a615aba4-cb3e-4e17-95bf-4659a57ae951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    492\n",
       "0    492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df = pd.concat([frauds, not_frauds.sample(len(frauds), random_state=1)])\n",
    "balanced_df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66a0ad51-0d1f-4f33-a5fa-3b755c8b857d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18372</th>\n",
       "      <td>0.170309</td>\n",
       "      <td>-1.762593</td>\n",
       "      <td>0.256143</td>\n",
       "      <td>1.683125</td>\n",
       "      <td>-1.279233</td>\n",
       "      <td>-1.902762</td>\n",
       "      <td>1.004210</td>\n",
       "      <td>-1.009748</td>\n",
       "      <td>-2.432546</td>\n",
       "      <td>0.458860</td>\n",
       "      <td>...</td>\n",
       "      <td>2.493579</td>\n",
       "      <td>0.320829</td>\n",
       "      <td>-0.535481</td>\n",
       "      <td>0.499401</td>\n",
       "      <td>-0.915196</td>\n",
       "      <td>-0.423434</td>\n",
       "      <td>0.107049</td>\n",
       "      <td>0.175922</td>\n",
       "      <td>2.906449</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96341</th>\n",
       "      <td>0.380388</td>\n",
       "      <td>1.227614</td>\n",
       "      <td>-0.668974</td>\n",
       "      <td>-0.271785</td>\n",
       "      <td>-0.589440</td>\n",
       "      <td>-0.604795</td>\n",
       "      <td>-0.350285</td>\n",
       "      <td>-0.486365</td>\n",
       "      <td>-0.010809</td>\n",
       "      <td>-0.794944</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026055</td>\n",
       "      <td>-0.295255</td>\n",
       "      <td>-0.180459</td>\n",
       "      <td>-0.436539</td>\n",
       "      <td>0.494649</td>\n",
       "      <td>-0.283738</td>\n",
       "      <td>-0.001128</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>1.062111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248296</th>\n",
       "      <td>0.890522</td>\n",
       "      <td>-0.613696</td>\n",
       "      <td>3.698772</td>\n",
       "      <td>-5.534941</td>\n",
       "      <td>5.620486</td>\n",
       "      <td>1.649263</td>\n",
       "      <td>-2.335145</td>\n",
       "      <td>-0.907188</td>\n",
       "      <td>0.706362</td>\n",
       "      <td>-3.747646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319261</td>\n",
       "      <td>-0.471379</td>\n",
       "      <td>-0.075890</td>\n",
       "      <td>-0.667909</td>\n",
       "      <td>-0.642848</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>0.488410</td>\n",
       "      <td>0.292345</td>\n",
       "      <td>-0.307413</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264328</th>\n",
       "      <td>0.933932</td>\n",
       "      <td>-0.011624</td>\n",
       "      <td>0.640413</td>\n",
       "      <td>0.868046</td>\n",
       "      <td>-0.505279</td>\n",
       "      <td>0.261938</td>\n",
       "      <td>0.223098</td>\n",
       "      <td>0.239049</td>\n",
       "      <td>0.150877</td>\n",
       "      <td>0.225142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069401</td>\n",
       "      <td>0.268024</td>\n",
       "      <td>0.261459</td>\n",
       "      <td>0.683742</td>\n",
       "      <td>-1.567901</td>\n",
       "      <td>-0.816674</td>\n",
       "      <td>0.185781</td>\n",
       "      <td>0.283021</td>\n",
       "      <td>-0.272619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208904</th>\n",
       "      <td>0.794730</td>\n",
       "      <td>-0.679341</td>\n",
       "      <td>1.217389</td>\n",
       "      <td>-0.316778</td>\n",
       "      <td>-1.086725</td>\n",
       "      <td>0.855349</td>\n",
       "      <td>-0.980760</td>\n",
       "      <td>0.970589</td>\n",
       "      <td>0.133116</td>\n",
       "      <td>-0.357671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083048</td>\n",
       "      <td>-0.137032</td>\n",
       "      <td>-0.238920</td>\n",
       "      <td>-0.617244</td>\n",
       "      <td>0.039020</td>\n",
       "      <td>-0.081848</td>\n",
       "      <td>0.234633</td>\n",
       "      <td>0.128382</td>\n",
       "      <td>-0.307273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81557</th>\n",
       "      <td>0.341393</td>\n",
       "      <td>-4.502731</td>\n",
       "      <td>-3.876484</td>\n",
       "      <td>1.341248</td>\n",
       "      <td>0.113400</td>\n",
       "      <td>0.189428</td>\n",
       "      <td>-0.560985</td>\n",
       "      <td>-0.140478</td>\n",
       "      <td>0.684651</td>\n",
       "      <td>0.475363</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.140218</td>\n",
       "      <td>0.049411</td>\n",
       "      <td>2.313731</td>\n",
       "      <td>0.252330</td>\n",
       "      <td>0.307219</td>\n",
       "      <td>0.859051</td>\n",
       "      <td>0.184033</td>\n",
       "      <td>-0.308269</td>\n",
       "      <td>4.227625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276071</th>\n",
       "      <td>0.965803</td>\n",
       "      <td>2.091900</td>\n",
       "      <td>-0.757459</td>\n",
       "      <td>-1.192258</td>\n",
       "      <td>-0.755458</td>\n",
       "      <td>-0.620324</td>\n",
       "      <td>-0.322077</td>\n",
       "      <td>-1.082511</td>\n",
       "      <td>0.117200</td>\n",
       "      <td>-0.140927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288253</td>\n",
       "      <td>0.831939</td>\n",
       "      <td>0.142007</td>\n",
       "      <td>0.592615</td>\n",
       "      <td>-0.196143</td>\n",
       "      <td>-0.136676</td>\n",
       "      <td>0.020182</td>\n",
       "      <td>-0.015470</td>\n",
       "      <td>-0.028645</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175971</th>\n",
       "      <td>0.709373</td>\n",
       "      <td>1.972989</td>\n",
       "      <td>0.157281</td>\n",
       "      <td>-1.715078</td>\n",
       "      <td>1.207451</td>\n",
       "      <td>0.681612</td>\n",
       "      <td>-0.615282</td>\n",
       "      <td>0.601791</td>\n",
       "      <td>-0.291935</td>\n",
       "      <td>-0.132265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098640</td>\n",
       "      <td>0.467533</td>\n",
       "      <td>-0.078973</td>\n",
       "      <td>-0.371882</td>\n",
       "      <td>0.486038</td>\n",
       "      <td>-0.490665</td>\n",
       "      <td>-0.018374</td>\n",
       "      <td>-0.070911</td>\n",
       "      <td>0.075735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27738</th>\n",
       "      <td>0.200727</td>\n",
       "      <td>-2.439237</td>\n",
       "      <td>2.591458</td>\n",
       "      <td>-2.840126</td>\n",
       "      <td>1.286244</td>\n",
       "      <td>-1.777016</td>\n",
       "      <td>-1.436139</td>\n",
       "      <td>-2.206056</td>\n",
       "      <td>-2.282725</td>\n",
       "      <td>-0.292885</td>\n",
       "      <td>...</td>\n",
       "      <td>1.774460</td>\n",
       "      <td>-0.771390</td>\n",
       "      <td>0.065727</td>\n",
       "      <td>0.103916</td>\n",
       "      <td>-0.057578</td>\n",
       "      <td>0.242652</td>\n",
       "      <td>-0.268649</td>\n",
       "      <td>-0.743713</td>\n",
       "      <td>1.443443</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156988</th>\n",
       "      <td>0.632535</td>\n",
       "      <td>0.745153</td>\n",
       "      <td>2.809299</td>\n",
       "      <td>-5.825406</td>\n",
       "      <td>5.835566</td>\n",
       "      <td>0.512320</td>\n",
       "      <td>-0.615622</td>\n",
       "      <td>-2.916576</td>\n",
       "      <td>0.776710</td>\n",
       "      <td>-1.878832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284841</td>\n",
       "      <td>-0.874383</td>\n",
       "      <td>-0.083995</td>\n",
       "      <td>-0.651442</td>\n",
       "      <td>0.454594</td>\n",
       "      <td>0.050376</td>\n",
       "      <td>0.756953</td>\n",
       "      <td>0.383869</td>\n",
       "      <td>-0.307413</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "18372   0.170309 -1.762593  0.256143  1.683125 -1.279233 -1.902762  1.004210   \n",
       "96341   0.380388  1.227614 -0.668974 -0.271785 -0.589440 -0.604795 -0.350285   \n",
       "248296  0.890522 -0.613696  3.698772 -5.534941  5.620486  1.649263 -2.335145   \n",
       "264328  0.933932 -0.011624  0.640413  0.868046 -0.505279  0.261938  0.223098   \n",
       "208904  0.794730 -0.679341  1.217389 -0.316778 -1.086725  0.855349 -0.980760   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "81557   0.341393 -4.502731 -3.876484  1.341248  0.113400  0.189428 -0.560985   \n",
       "276071  0.965803  2.091900 -0.757459 -1.192258 -0.755458 -0.620324 -0.322077   \n",
       "175971  0.709373  1.972989  0.157281 -1.715078  1.207451  0.681612 -0.615282   \n",
       "27738   0.200727 -2.439237  2.591458 -2.840126  1.286244 -1.777016 -1.436139   \n",
       "156988  0.632535  0.745153  2.809299 -5.825406  5.835566  0.512320 -0.615622   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "18372  -1.009748 -2.432546  0.458860  ...  2.493579  0.320829 -0.535481   \n",
       "96341  -0.486365 -0.010809 -0.794944  ... -0.026055 -0.295255 -0.180459   \n",
       "248296 -0.907188  0.706362 -3.747646  ...  0.319261 -0.471379 -0.075890   \n",
       "264328  0.239049  0.150877  0.225142  ...  0.069401  0.268024  0.261459   \n",
       "208904  0.970589  0.133116 -0.357671  ... -0.083048 -0.137032 -0.238920   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "81557  -0.140478  0.684651  0.475363  ... -0.140218  0.049411  2.313731   \n",
       "276071 -1.082511  0.117200 -0.140927  ...  0.288253  0.831939  0.142007   \n",
       "175971  0.601791 -0.291935 -0.132265  ...  0.098640  0.467533 -0.078973   \n",
       "27738  -2.206056 -2.282725 -0.292885  ...  1.774460 -0.771390  0.065727   \n",
       "156988 -2.916576  0.776710 -1.878832  ...  0.284841 -0.874383 -0.083995   \n",
       "\n",
       "             V24       V25       V26       V27       V28    Amount  Class  \n",
       "18372   0.499401 -0.915196 -0.423434  0.107049  0.175922  2.906449      0  \n",
       "96341  -0.436539  0.494649 -0.283738 -0.001128  0.035075  1.062111      1  \n",
       "248296 -0.667909 -0.642848  0.070600  0.488410  0.292345 -0.307413      1  \n",
       "264328  0.683742 -1.567901 -0.816674  0.185781  0.283021 -0.272619      0  \n",
       "208904 -0.617244  0.039020 -0.081848  0.234633  0.128382 -0.307273      0  \n",
       "...          ...       ...       ...       ...       ...       ...    ...  \n",
       "81557   0.252330  0.307219  0.859051  0.184033 -0.308269  4.227625      0  \n",
       "276071  0.592615 -0.196143 -0.136676  0.020182 -0.015470 -0.028645      1  \n",
       "175971 -0.371882  0.486038 -0.490665 -0.018374 -0.070911  0.075735      0  \n",
       "27738   0.103916 -0.057578  0.242652 -0.268649 -0.743713  1.443443      1  \n",
       "156988 -0.651442  0.454594  0.050376  0.756953  0.383869 -0.307413      1  \n",
       "\n",
       "[984 rows x 31 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df = balanced_df.sample(frac=1, random_state=1)\n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6841d28b-ac30-44b3-8858-cc4f8c1b3485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700, 30), (700,), (142, 30), (142,), (142, 30), (142,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df = balanced_df.sample(frac = 1, random_state = 1)\n",
    "\n",
    "balanced_df_np = balanced_df.to_numpy()\n",
    "\n",
    "x_train_b, y_train_b = balanced_df_np[:700, :-1], balanced_df_np[:700, -1].astype(int)\n",
    "x_test_b, y_test_b = balanced_df_np[700:842, :-1], balanced_df_np[700:842, -1].astype(int)\n",
    "x_val_b, y_val_b = balanced_df_np[842:, :-1], balanced_df_np[842:, -1].astype(int)\n",
    "x_train_b.shape, y_train_b.shape, x_test_b.shape, y_test_b.shape, x_val_b.shape, y_val_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "232edde7-6c14-4997-9c43-a5072a54c0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    358\n",
       " 1    342\n",
       " dtype: int64,\n",
       " 1    74\n",
       " 0    68\n",
       " dtype: int64,\n",
       " 1    76\n",
       " 0    66\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train_b).value_counts(), pd.Series(y_test_b).value_counts(), pd.Series(y_val_b).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54cb154-6420-4262-96e4-09e9c89eb600",
   "metadata": {},
   "source": [
    "## Shallow neural network on balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c5be448-9cc2-4f3b-900c-55bf0d5ce4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7479 - accuracy: 0.4657 - val_loss: 0.7379 - val_accuracy: 0.4085\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 2/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7111 - accuracy: 0.5186 - val_loss: 0.6894 - val_accuracy: 0.5352\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 3/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5800 - val_loss: 0.6373 - val_accuracy: 0.6338\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 4/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.6843 - val_loss: 0.5793 - val_accuracy: 0.7606\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 5/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.7686 - val_loss: 0.5380 - val_accuracy: 0.8099\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 6/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.8171 - val_loss: 0.5206 - val_accuracy: 0.8169\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 7/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.8171 - val_loss: 0.5103 - val_accuracy: 0.8239\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 8/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.8271 - val_loss: 0.5007 - val_accuracy: 0.8380\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 9/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.8243 - val_loss: 0.4933 - val_accuracy: 0.8380\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 10/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.8386 - val_loss: 0.4859 - val_accuracy: 0.8380\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 11/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.8543 - val_loss: 0.4782 - val_accuracy: 0.8380\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 12/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.8557 - val_loss: 0.4710 - val_accuracy: 0.8380\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 13/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.8586 - val_loss: 0.4626 - val_accuracy: 0.8380\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 14/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.8657 - val_loss: 0.4550 - val_accuracy: 0.8380\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 15/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8671 - val_loss: 0.4469 - val_accuracy: 0.8451\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 16/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8714 - val_loss: 0.4404 - val_accuracy: 0.8592\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 17/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8686 - val_loss: 0.4340 - val_accuracy: 0.8662\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 18/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8771 - val_loss: 0.4269 - val_accuracy: 0.8592\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 19/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8843 - val_loss: 0.4188 - val_accuracy: 0.8592\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 20/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3914 - accuracy: 0.8743 - val_loss: 0.4115 - val_accuracy: 0.8592\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 21/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8871 - val_loss: 0.4051 - val_accuracy: 0.8592\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 22/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8871 - val_loss: 0.3975 - val_accuracy: 0.8592\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 23/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8900 - val_loss: 0.3910 - val_accuracy: 0.8592\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 24/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3478 - accuracy: 0.9071 - val_loss: 0.3854 - val_accuracy: 0.8592\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 25/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.9100 - val_loss: 0.3787 - val_accuracy: 0.8662\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 26/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8971 - val_loss: 0.3713 - val_accuracy: 0.8662\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 27/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.9029 - val_loss: 0.3634 - val_accuracy: 0.8662\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 28/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.9100 - val_loss: 0.3587 - val_accuracy: 0.8662\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 29/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.9114 - val_loss: 0.3528 - val_accuracy: 0.8662\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 30/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.9100 - val_loss: 0.3470 - val_accuracy: 0.8662\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0554509730>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shallow_nn_b = Sequential()\n",
    "shallow_nn_b.add(InputLayer((x_train.shape[1],)))\n",
    "shallow_nn_b.add(Dense(1, 'relu'))\n",
    "shallow_nn_b.add(BatchNormalization())\n",
    "shallow_nn_b.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "checkpoint = ModelCheckpoint('shallow_nn_b', save_best_only=True)\n",
    "shallow_nn_b.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "shallow_nn_b.fit(x_train_b, y_train_b, validation_data=(x_val_b, y_val_b), epochs=30, callbacks=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "760220da-feeb-43b3-88aa-68d8c4c510c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3054 - accuracy: 0.9200 - val_loss: 0.3412 - val_accuracy: 0.8662\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 2/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.9157 - val_loss: 0.3355 - val_accuracy: 0.8662\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 3/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.9071 - val_loss: 0.3309 - val_accuracy: 0.8662\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 4/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2978 - accuracy: 0.9057 - val_loss: 0.3286 - val_accuracy: 0.8662\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 5/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2886 - accuracy: 0.9086 - val_loss: 0.3246 - val_accuracy: 0.8662\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 6/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2771 - accuracy: 0.9257 - val_loss: 0.3206 - val_accuracy: 0.8662\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 7/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2754 - accuracy: 0.9200 - val_loss: 0.3168 - val_accuracy: 0.8732\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 8/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2672 - accuracy: 0.9200 - val_loss: 0.3139 - val_accuracy: 0.8803\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 9/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2698 - accuracy: 0.9143 - val_loss: 0.3109 - val_accuracy: 0.8873\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 10/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2540 - accuracy: 0.9243 - val_loss: 0.3096 - val_accuracy: 0.8944\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 11/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2612 - accuracy: 0.9229 - val_loss: 0.3050 - val_accuracy: 0.8944\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 12/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.9257 - val_loss: 0.3027 - val_accuracy: 0.8944\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 13/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.9214 - val_loss: 0.3001 - val_accuracy: 0.8944\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 14/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.9286 - val_loss: 0.2988 - val_accuracy: 0.9014\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 15/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2436 - accuracy: 0.9257 - val_loss: 0.2958 - val_accuracy: 0.9014\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 16/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2381 - accuracy: 0.9243 - val_loss: 0.2936 - val_accuracy: 0.9014\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 17/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2327 - accuracy: 0.9329 - val_loss: 0.2918 - val_accuracy: 0.8944\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 18/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2342 - accuracy: 0.9229 - val_loss: 0.2892 - val_accuracy: 0.8944\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 19/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2324 - accuracy: 0.9314 - val_loss: 0.2880 - val_accuracy: 0.8944\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 20/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.9229 - val_loss: 0.2861 - val_accuracy: 0.8944\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 21/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2272 - accuracy: 0.9286 - val_loss: 0.2847 - val_accuracy: 0.8944\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 22/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2198 - accuracy: 0.9357 - val_loss: 0.2832 - val_accuracy: 0.8944\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 23/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2339 - accuracy: 0.9271 - val_loss: 0.2810 - val_accuracy: 0.8944\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 24/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9286 - val_loss: 0.2806 - val_accuracy: 0.8944\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 25/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2216 - accuracy: 0.9343 - val_loss: 0.2792 - val_accuracy: 0.8944\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 26/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.9329 - val_loss: 0.2794 - val_accuracy: 0.8944\n",
      "Epoch 27/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2163 - accuracy: 0.9286 - val_loss: 0.2783 - val_accuracy: 0.8944\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 28/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2152 - accuracy: 0.9300 - val_loss: 0.2752 - val_accuracy: 0.8944\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 29/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2149 - accuracy: 0.9329 - val_loss: 0.2751 - val_accuracy: 0.8944\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n",
      "Epoch 30/30\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.9371 - val_loss: 0.2743 - val_accuracy: 0.8944\n",
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0547d885b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shallow_nn_b.fit(x_train_b, y_train_b, validation_data=(x_val_b, y_val_b), epochs=30, callbacks=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e278c530-8b03-4764-83ff-f6dcb592b7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       0.84      0.95      0.89        66\n",
      "       Fraud       0.96      0.84      0.90        76\n",
      "\n",
      "    accuracy                           0.89       142\n",
      "   macro avg       0.90      0.90      0.89       142\n",
      "weighted avg       0.90      0.89      0.89       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val_b, neural_net_predictions(shallow_nn_b, x_val_b), target_names=['Not Fraud', 'Fraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33cc6ff-3c1a-45e0-aaf2-893238700314",
   "metadata": {},
   "source": [
    "## ML models on balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdf93719-b4ab-4403-9702-53f26fbcfa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       0.65      1.00      0.79        66\n",
      "       Fraud       1.00      0.53      0.69        76\n",
      "\n",
      "    accuracy                           0.75       142\n",
      "   macro avg       0.82      0.76      0.74       142\n",
      "weighted avg       0.84      0.75      0.73       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_b = RandomForestClassifier(max_depth=2, n_jobs=-1)\n",
    "rf_b.fit(x_train_b, y_train_b)\n",
    "print(classification_report(y_val_b, rf.predict(x_val_b), target_names=['Not Fraud', 'Fraud']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62b0f177-3745-4324-bb6d-6e0b43774b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       0.66      1.00      0.80        66\n",
      "       Fraud       1.00      0.55      0.71        76\n",
      "\n",
      "    accuracy                           0.76       142\n",
      "   macro avg       0.83      0.78      0.75       142\n",
      "weighted avg       0.84      0.76      0.75       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbc_b = GradientBoostingClassifier(n_estimators=50, learning_rate=1.0, max_depth=2, random_state=0)\n",
    "gbc_b.fit(x_train_b, y_train_b)\n",
    "print(classification_report(y_val_b, gbc.predict(x_val_b), target_names=['Not Fraud', 'Fraud']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2c17dae-de46-4fa2-8889-9287ab1efd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       0.77      1.00      0.87        66\n",
      "       Fraud       1.00      0.74      0.85        76\n",
      "\n",
      "    accuracy                           0.86       142\n",
      "   macro avg       0.88      0.87      0.86       142\n",
      "weighted avg       0.89      0.86      0.86       142\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stepski/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "svc_b = LinearSVC(class_weight='balanced')\n",
    "svc_b.fit(x_train_b, y_train_b)\n",
    "print(classification_report(y_val_b, svc.predict(x_val_b), target_names=['Not Fraud', 'Fraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebffebdb-80e3-4149-8c54-80df9eb2efbd",
   "metadata": {},
   "source": [
    "### Score for selected Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d95d9cf-0809-4d7d-b3bb-2129c6f159a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       0.82      1.00      0.90        68\n",
      "       Fraud       1.00      0.80      0.89        74\n",
      "\n",
      "    accuracy                           0.89       142\n",
      "   macro avg       0.91      0.90      0.89       142\n",
      "weighted avg       0.91      0.89      0.89       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_b, neural_net_predictions(shallow_nn_b, x_test_b), target_names=['Not Fraud', 'Fraud']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce18d4e8-380f-4313-9dfb-451640f7766e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
